{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from euclidean_classifier import EuclideanClassifier\n",
    "from collections import defaultdict\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(data_type):\n",
    "\n",
    "    dir = './pr_lab1_2016-17_data/' + data_type + '.txt'\n",
    "    with open(dir, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        # random.shuffle(lines)\n",
    "\n",
    "    features, digits = [], []\n",
    "    for line in lines:\n",
    "        line = [float(i) for i in line.rstrip().split(\" \")]\n",
    "        features.append(line[1:])\n",
    "        digits.append(int(line[0]))\n",
    "\n",
    "    return np.asarray(features), np.asarray(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(points):\n",
    "\n",
    "    vor = Voronoi(points)\n",
    "    voronoi_plot_2d(vor,show_points=False, show_vertices=False)\n",
    "    plt.scatter(points[:,0], points[:,1], c=range(10), s=50, edgecolor = 'k')\n",
    "    cdict = {0 : 'red', 1 : 'blue', 2 : 'gold', 3 : 'purple', 4 : 'darkgreen', 5 : 'orange', 6 : 'lime', 7 : 'cyan', 8 : 'magenta', 9 : 'dimgray'}\n",
    "\n",
    "    for point,label in zip(points,range(10)):\n",
    "        plt.scatter(point[0], point[1], c=cdict[label], label = label, s = 500)\n",
    "        label += 1\n",
    "    plt.legend(prop={'size':20})\n",
    "    plt.title('Decision Boundaries', fontsize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score using 5-fold cross-validation is: 0.841773724173982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EuclideanClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = readData('train')\n",
    "X_test, y_test = readData('test')\n",
    "\n",
    "n_samples, n_features = X_train.shape\n",
    "n_test_samples, _ = X_test.shape\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "# # Euclidean Classifier\n",
    "clf = EuclideanClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "# print(clf.score(X_test, y_test))\n",
    "\n",
    "# 5-Fold Cross-Validation\n",
    "X = np.concatenate((X_train, X_test), axis = 0)\n",
    "y = np.concatenate((y_train, y_test), axis = 0)\n",
    "average_score = np.mean(cross_val_score(EuclideanClassifier(), X, y, cv = 5))\n",
    "print(\"The average score using 5-fold cross-validation is:\", average_score)\n",
    "\n",
    "\n",
    "# PCA 256 to 2 dims => for Decision Boundaries visualization\n",
    "X_train_reduced = PCA(n_components=2).fit_transform(X_train)\n",
    "X_test_reduced = PCA(n_components=2).fit_transform(X_test)\n",
    "\n",
    "clf2 = EuclideanClassifier()\n",
    "clf2.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14 - a priori probabilities\n",
    "labels, counts = np.unique(y_train, return_counts = True)\n",
    "a_priori = defaultdict(lambda : 0, {})\n",
    "for label, cnt in zip(labels, counts):\n",
    "    a_priori[label] = cnt / y_train.size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    digit_count = np.zeros(n_classes)\n",
    "    digit_mean = np.zeros((n_classes, n_features))\n",
    "    digit_var = np.zeros((n_classes, n_features))\n",
    "    \n",
    "#   Digit Count and Mean\n",
    "    for i in range(n_samples):\n",
    "        digit = y_train[i]\n",
    "        digit_count[digit] = digit_count[digit] + 1\n",
    "        digit_mean[digit] = digit_mean[digit] + X_train[i]\n",
    "\n",
    "    for digit in range(n_classes):\n",
    "        digit_mean[digit] = digit_mean[digit] / digit_count[digit]\n",
    "        \n",
    "#   Digit Variance\n",
    "    for i in range(n_samples):\n",
    "        digit = y_train[i]\n",
    "        digit_var[digit] = digit_var[digit] + (X_train[i] - digit_mean[digit])**2\n",
    "\n",
    "    for digit in range(n_classes):\n",
    "        digit_var[digit] = digit_var[digit] / (digit_count[digit] - 1)\n",
    "    \n",
    "#   zero variance values are changed to epsilon\n",
    "    digit_var[digit_var == 0] = np.finfo(np.float32).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17588440458395616\n"
     ]
    }
   ],
   "source": [
    "\n",
    "id = 0\n",
    "acc = 0\n",
    "for j in range(n_test_samples):\n",
    "    maxim = 0\n",
    "    for i in range(10):\n",
    "        prob = a_priori[i]*multivariate_normal.logpdf(X_test[j], mean = digit_mean[i], cov = np.diag(digit_var[i]))\n",
    "        if ( prob >= maxim):\n",
    "            id = i\n",
    "    acc += (id == y_test[j])\n",
    "print(acc/n_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
