{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from euclidean_classifier import EuclideanClassifier\n",
    "from collections import defaultdict\n",
    "from scipy.stats import multivariate_normal\n",
    "from naive_bayes_classifier import NaiveBayesClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(data_type):\n",
    "\n",
    "    dir = './pr_lab1_2016-17_data/' + data_type + '.txt'\n",
    "    with open(dir, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "        # random.shuffle(lines)\n",
    "\n",
    "    features, digits = [], []\n",
    "    for line in lines:\n",
    "        line = [float(i) for i in line.rstrip().split(\" \")]\n",
    "        features.append(line[1:])\n",
    "        digits.append(int(line[0]))\n",
    "\n",
    "    return np.asarray(features), np.asarray(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(points):\n",
    "\n",
    "    vor = Voronoi(points)\n",
    "    voronoi_plot_2d(vor,show_points=False, show_vertices=False)\n",
    "    plt.scatter(points[:,0], points[:,1], c=range(10), s=50, edgecolor = 'k')\n",
    "    cdict = {0 : 'red', 1 : 'blue', 2 : 'gold', 3 : 'purple', 4 : 'darkgreen', 5 : 'orange', 6 : 'lime', 7 : 'cyan', 8 : 'magenta', 9 : 'dimgray'}\n",
    "\n",
    "    for point,label in zip(points,range(10)):\n",
    "        plt.scatter(point[0], point[1], c=cdict[label], label = label, s = 500)\n",
    "        label += 1\n",
    "    plt.legend(prop={'size':20})\n",
    "    plt.title('Decision Boundaries', fontsize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score using 5-fold cross-validation is: 0.841773724173982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EuclideanClassifier()"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = readData('train')\n",
    "X_test, y_test = readData('test')\n",
    "\n",
    "n_samples, n_features = X_train.shape\n",
    "n_test_samples, _ = X_test.shape\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "# # Euclidean Classifier\n",
    "clf = EuclideanClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "# print(clf.score(X_test, y_test))\n",
    "\n",
    "# 5-Fold Cross-Validation\n",
    "X = np.concatenate((X_train, X_test), axis = 0)\n",
    "y = np.concatenate((y_train, y_test), axis = 0)\n",
    "average_score = np.mean(cross_val_score(EuclideanClassifier(), X, y, cv = 5))\n",
    "print(\"The average score using 5-fold cross-validation is:\", average_score)\n",
    "\n",
    "\n",
    "# PCA 256 to 2 dims => for Decision Boundaries visualization\n",
    "X_train_reduced = PCA(n_components=2).fit_transform(X_train)\n",
    "X_test_reduced = PCA(n_components=2).fit_transform(X_test)\n",
    "\n",
    "clf2 = EuclideanClassifier()\n",
    "clf2.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14 - a priori probabilities\n",
    "labels, counts = np.unique(y_train, return_counts = True)\n",
    "a_priori = defaultdict(lambda : 0, {})\n",
    "for label, cnt in zip(labels, counts):\n",
    "    a_priori[label] = cnt / y_train.size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "    digit_count = np.zeros(n_classes)\n",
    "    digit_mean = np.zeros((n_classes, n_features))\n",
    "#     digit_var = np.zeros((n_classes, n_features))\n",
    "    \n",
    "#   Digit Count and Mean\n",
    "    for i in range(n_samples):\n",
    "        digit = y_train[i]\n",
    "        digit_count[digit] = digit_count[digit] + 1\n",
    "        digit_mean[digit] = digit_mean[digit] + X_train[i]\n",
    "\n",
    "    for digit in range(n_classes):\n",
    "        digit_mean[digit] = digit_mean[digit] / digit_count[digit]\n",
    "    \n",
    "    \n",
    "    digit_var = defaultdict(lambda : None, {})        \n",
    "    for label in labels:\n",
    "        digit_var[label] = np.var(X_train[y_train == label], axis = 0)\n",
    "        digit_var[label][digit_var[label] == 0] = 1.0e-8\n",
    "#         digit_var[label][digit_var[label] == 0] = np.finfo(np.float32).eps\n",
    "#         print(np.amax(digit_var[label]))\n",
    "    \n",
    "# #   Digit Variance\n",
    "#     for i in range(n_samples):\n",
    "#         digit = y_train[i]\n",
    "#         digit_var[digit] = digit_var[digit] + (X_train[i] - digit_mean[digit])**2\n",
    "\n",
    "#     for digit in range(n_classes):\n",
    "#         digit_var[digit] = digit_var[digit] / (digit_count[digit] - 1)\n",
    "    \n",
    "#   zero variance values are changed to epsilon\n",
    "#     digit_var[digit_var == 0] = np.finfo(np.float32).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32884902840059793\n"
     ]
    }
   ],
   "source": [
    "#         prob1 = -128*np.log(2*np.pi)\n",
    "#         prob1 += -0.5*np.log(np.linalg.det(cov)) \n",
    "#         prob1 += -0.5*np.matmul(np.matmul(np.matrix.transpose(X_test[j]-mean),np.linalg.inv(cov)),X_test[j]-mean) \n",
    "#         prob = np.log(a_priori[i]) + prob1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "id = 0\n",
    "acc = 0\n",
    "for j in range(n_test_samples):\n",
    "    maxim = 0\n",
    "    for i in range(10):\n",
    "        mean = digit_mean[i]\n",
    "        cov = np.diag(digit_var[i])\n",
    "        prob = np.log(a_priori[i]) + multivariate_normal.logpdf(X_test[j], mean = mean, cov = cov)\n",
    "        if ( prob >= maxim):\n",
    "            id = i\n",
    "            maxim = prob\n",
    "    acc += (id == y_test[j])\n",
    "print(acc/n_test_samples)\n",
    "# multivariate_normal.pdf(X_test[0], mean = digit_mean[9], cov = np.diag(digit_var[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gau_pixel(x, m, v):\n",
    "    return -0.5*np.log(2*np.pi * v) - 0.5*(((x - m)**2 )/ v) \n",
    "\n",
    "def gau_image(xs, ms, vs):\n",
    "    prob = 0\n",
    "    for x, m, v in zip(xs, ms, vs):\n",
    "        prob += gau_pixel(x, m, v)\n",
    "    \n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7254608868958645\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i in range(n_test_samples):\n",
    "    maxi = float(\"-inf\")\n",
    "    idi = 0\n",
    "    for j in range(n_classes):\n",
    "        prob1 = gau_image(X_test[i], digit_mean[j], digit_var[j])\n",
    "        prob2 = np.log(a_priori[j])\n",
    "        if (prob1 + prob2) >= maxi:\n",
    "            idi = j\n",
    "            maxi = prob1 + prob2\n",
    "        \n",
    "    \n",
    "    if (idi == y_test[i]):\n",
    "        acc += 1\n",
    "\n",
    "print(acc/n_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpitoskas/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3506: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/home/jpitoskas/.local/lib/python3.6/site-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/jpitoskas/.local/lib/python3.6/site-packages/numpy/core/_methods.py:207: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (7291,256) into shape (256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-f9f231d70cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ΣΗΜΜΥ/Ροές/Σ/Αναγνώριση Προτύπων/Lab_1/naive_bayes_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;31m# a = y == idx2class[idx]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# x = X[y == idx2class[idx]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (7291,256) into shape (256)"
     ]
    }
   ],
   "source": [
    "clf = NaiveBayesClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "asd = np.array([1,2,3,4,5,1,1,1])\n",
    "print(asd[asd==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False,  True,  True,  True])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
