{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>Αναγνώριση Προτύπων - 2η Εργαστηριακή Άσκηση</h1> </center>\n",
    "\n",
    "---\n",
    "\n",
    "<center> <h2>Θέμα: Αναγνώριση φωνής με Κρυφά Μαρκοβιανά Μοντέλα και Αναδρομικά Νευρωνικά Δίκτυα</h2> </center>\n",
    "<center> <h2>ΣΧΟΛΗ: ΣΗΜΜΥ</h2> </center>\n",
    "<img src=\"pyrforos-digamma.png\" width=\"100\">\n",
    "\n",
    "Ονοματεπώνυμο | Αριθμός Μητρώου\n",
    "------------ | -------------\n",
    "Γιάννης Πιτόσκας | 03115077\n",
    "Αντώνης Παπαοικονόμου | 03115140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\python36\\lib\\site-packages (19.3.1)\n",
      "Requirement already up-to-date: scikit-learn in c:\\python36\\lib\\site-packages (0.22)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\python36\\lib\\site-packages (from scikit-learn) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\python36\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\python36\\lib\\site-packages (from scikit-learn) (0.14.1)\n",
      "Collecting numpy\n",
      "  Downloading https://files.pythonhosted.org/packages/ec/23/75dfc62331c8c49f073051512718f3f36ee67cf3be290f58b4b03ec3cb51/numpy-1.18.0-cp36-cp36m-win_amd64.whl (12.8MB)\n",
      "Installing collected packages: numpy\n",
      "  Found existing installation: numpy 1.17.4\n",
      "    Uninstalling numpy-1.17.4:\n",
      "      Successfully uninstalled numpy-1.17.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\python36\\\\lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: joblib in c:\\python36\\lib\\site-packages (0.14.1)\n",
      "Collecting librosa\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/71/c21ccef81276d85b9e3a36d80dad5baaf8a91f912e65eff0fd0d74a5a19c/librosa-0.7.1.tar.gz (1.6MB)\n",
      "Collecting audioread>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/0b/940ea7861e0e9049f09dcfd72a90c9ae55f697c17c299a323f0148f913d2/audioread-2.1.8.tar.gz\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\python36\\lib\\site-packages (from librosa) (1.18.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\python36\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\python36\\lib\\site-packages (from librosa) (0.22)\n",
      "Requirement already satisfied: joblib>=0.12 in c:\\python36\\lib\\site-packages (from librosa) (0.14.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\python36\\lib\\site-packages (from librosa) (4.4.1)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\anton\\appdata\\roaming\\python\\python36\\site-packages (from librosa) (1.12.0)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/79/75/e22272b9c2185fc8f3af6ce37229708b45e8b855fd4bc38b4d6b040fff65/resampy-0.2.2.tar.gz (323kB)\n",
      "Collecting numba>=0.43.0\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/ec/74adabcc82e2dd53d0d11f69efc75a08422bf849ab088f253b8e622f34ce/numba-0.46.0-cp36-cp36m-win_amd64.whl (2.0MB)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/de/24e4035f06540ebb4e9993238ede787063875b003e79c537511d32a74d29/SoundFile-0.10.3.post1-py2.py3.cp26.cp27.cp32.cp33.cp34.cp35.cp36.pp27.pp32.pp33-none-win_amd64.whl (689kB)\n",
      "Collecting llvmlite>=0.30.0dev0\n",
      "  Downloading https://files.pythonhosted.org/packages/44/60/894615d70d4bfbb9d6b035354b5d72a2a0d5fefc579f8405d750e062cf77/llvmlite-0.30.0-cp36-cp36m-win_amd64.whl (13.6MB)\n",
      "Collecting cffi>=1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/99/1adcccd6f7761186eb70e4591f45e941529fbf8e5df8e2d79e914887b118/cffi-1.13.2-cp36-cp36m-win_amd64.whl (175kB)\n",
      "Collecting pycparser\n",
      "  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
      "Installing collected packages: audioread, llvmlite, numba, resampy, pycparser, cffi, soundfile, librosa\n",
      "    Running setup.py install for audioread: started\n",
      "    Running setup.py install for audioread: finished with status 'done'\n",
      "    Running setup.py install for resampy: started\n",
      "    Running setup.py install for resampy: finished with status 'done'\n",
      "    Running setup.py install for pycparser: started\n",
      "    Running setup.py install for pycparser: finished with status 'done'\n",
      "    Running setup.py install for librosa: started\n",
      "    Running setup.py install for librosa: finished with status 'done'\n",
      "Successfully installed audioread-2.1.8 cffi-1.13.2 librosa-0.7.1 llvmlite-0.30.0 numba-0.46.0 pycparser-2.19 resampy-0.2.2 soundfile-0.10.3.post1\n",
      "Requirement already satisfied: pomegranate in c:\\python36\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\python36\\lib\\site-packages (from pomegranate) (2.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\python36\\lib\\site-packages (from pomegranate) (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.9.0b4 in c:\\python36\\lib\\site-packages (from pomegranate) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.8.0 in c:\\python36\\lib\\site-packages (from pomegranate) (1.18.0)\n",
      "Requirement already satisfied: pyyaml in c:\\python36\\lib\\site-packages (from pomegranate) (5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\python36\\lib\\site-packages (from networkx>=2.0->pomegranate) (4.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!pip3 install scikit-learn --upgrade\n",
    "!pip3 install numpy --upgrade\n",
    "!pip3 install --upgrade joblib\n",
    "!pip3 install librosa\n",
    "!pip3 install pomegranate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\Documents\\Αντώνης\\HMMY\\ΡΟΗ_Σ\\Αναγνώριση_Προτύπων\\Lab_2\\free-spoken-digit-dataset-master\\recordings\n",
      "G:\\Documents\\Αντώνης\\HMMY\\ΡΟΗ_Σ\\Αναγνώριση_Προτύπων\\Lab_2\\free-spoken-digit-dataset-master\\recordings\\0_jackson_0.wav G:\\Documents\\Αντώνης\\HMMY\\ΡΟΗ_Σ\\Αναγνώριση_Προτύπων\\Lab_2\\free-spoken-digit-dataset-master\\recordings\\0_jackson_1.wav\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bfca26f6c79f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mrecord_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./free-spoken-digit-dataset-master/recordings/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# os.chdir('./free-spoken-digit-dataset-master/recordings')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspk_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspk_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;31m# os.chdir('../../')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-bfca26f6c79f>\u001b[0m in \u001b[0;36mparser\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mfnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-bfca26f6c79f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mfnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def parser(directory):\n",
    "    # Parse relevant dataset info\n",
    "    print(directory)\n",
    "    files = glob(os.path.join(directory, '*.wav'))\n",
    "    print(files[0], files[1])\n",
    "    fnames = [f.split('/')[1].split('.')[0].split('_') for f in files]\n",
    "    print(fnames[0], fnames[1])\n",
    "    ids = [f[2] for f in fnames]\n",
    "    y = [int(f[0]) for f in fnames]\n",
    "    speakers = [f[1] for f in fnames]\n",
    "    _, Fs = librosa.core.load(files[0], sr=None)\n",
    "\n",
    "    def read_wav(f):\n",
    "        global Fs\n",
    "        wav, fs = librosa.core.load(f, sr=None)\n",
    "        return wav\n",
    "\n",
    "    # Read all wavs\n",
    "    wavs = [read_wav(f) for f in files]\n",
    "\n",
    "    # Extract MFCCs for all wavs\n",
    "    window = 30 * Fs // 1000\n",
    "    step = window // 2\n",
    "    frames = [librosa.feature.mfcc(wav, Fs, n_fft=window, hop_length=window - step, n_mfcc=6).T for wav in wavs]\n",
    "    # Print dataset info\n",
    "    print('Total wavs: {}'.format(len(frames)))\n",
    "\n",
    "    # Standardize data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(np.concatenate(frames))\n",
    "    for i in range(len(frames)):\n",
    "        frames[i] = scaler.transform(frames[i])\n",
    "\n",
    "    # Split to train-test\n",
    "    X_train, y_train, spk_train = [], [], []\n",
    "    X_test, y_test, spk_test = [], [], []\n",
    "    test_indices = ['0', '1', '2', '3', '4']\n",
    "    for idx, frame, label, spk in zip(ids, frames, y, speakers):\n",
    "        if str(idx) in test_indices:\n",
    "            X_test.append(frame)\n",
    "            y_test.append(label)\n",
    "       ## Βήμα 9     spk_test.append(spk)\n",
    "       ## Βήμα 9 else:\n",
    "            X_train.append(frame)\n",
    "            y_train.append(label)\n",
    "            spk_train.append(spk)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, spk_train, spk_test\n",
    "\n",
    "record_dir = os.path.abspath(\"./free-spoken-digit-dataset-master/recordings/\")\n",
    "# os.chdir('./free-spoken-digit-dataset-master/recordings')\n",
    "X, X_test, y, y_test, spk_train, spk_test = parser(record_dir)\n",
    "# os.chdir('../../')\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pomegranate import *\n",
    "\n",
    "X_digit = {digit : np.concatenate(X_train[y_train==digit]) for digit in range(10)}\n",
    "\n",
    "X0 = X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 5 # the number of HMM states\n",
    "n_mixtures = 2 # the number of Gaussians\n",
    "\n",
    "dists = [] # list of probability distributions for the HMM states\n",
    "for i in range(n_states):\n",
    "    a = GeneralMixtureModel.from_samples(MultivariateGaussianDistribution, n_mixtures, X0)\n",
    "    dists.append(a)\n",
    "    \n",
    "trans_mat = np.diag(np.ones(n_states-1), k=1) # your transition matrix\n",
    "starts = [1] + [0]*(n_states-1) # your starting probability matrix\n",
    "ends = [0]*(n_states-1) + [1] # your ending probability matrix\n",
    "\n",
    "\n",
    "\n",
    "data = [] # your data: must be a Python list that contains: 2D lists with the sequences (so its dimension would be num_sequences x seq_length x feature_dimension)\n",
    "          # But be careful, it is not a numpy array, it is a Python list (so each sequence can have different length)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
