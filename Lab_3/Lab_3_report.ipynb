{"cells":[{"metadata":{"_cell_guid":"58a4b548-a984-4fdb-9724-30cf9bad07b7","_uuid":"a44653a1-828c-497c-af50-138998251e32"},"cell_type":"markdown","source":"<center> <h1>Αναγνώριση Προτύπων - 3η Εργαστηριακή Άσκηση</h1> </center>\n\n---\n\n<center> <h2>Θέμα: Αναγνώριση Είδους και Εξαγωγή Συναισθήματος από Μουσική</h2> </center>\n<center> <h2>ΣΧΟΛΗ: ΣΗΜΜΥ</h2> </center>\n\nΟνοματεπώνυμο | Αριθμός Μητρώου\n------------ | -------------\nΓιάννης Πιτόσκας | 03115077\nΑντώνης Παπαοικονόμου | 03115140"},{"metadata":{"_cell_guid":"67996755-c08c-46f0-894f-f2cd676348dd","_uuid":"ed933f14-ba37-4df7-acfc-30e4d34004fc"},"cell_type":"markdown","source":"# Βήμα 0"},{"metadata":{"_cell_guid":"a69f4358-1cf2-4256-9381-8f4d87c39d5b","_kg_hide-output":true,"_uuid":"04e70e9e-d6bc-4e8b-8e63-5be80f317de3","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\ndata_path = \"../input/patreco3-multitask-affective-music/data/\"\n# data_path = os.path.abspath(\"Q:\\Files\\patreco3-multitask-affective-music\\data\")\n# data_path = os.path.abspath(\"/Volumes/Ext HDD/Files/patreco3-multitask-affective-music/data\")\n\nprint(os.listdir(data_path))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f521c613-61bb-4eca-a254-171dcd73b2b1","_uuid":"a5ed85ad-e556-4c74-8855-caddaa8c2d4a"},"cell_type":"markdown","source":"# Βήμα 1"},{"metadata":{"_cell_guid":"f37f07ff-fa76-4223-9c5a-b6d29ebf38cf","_uuid":"4d002073-bfc2-4fd3-aab3-b79fbfc0e9b3"},"cell_type":"markdown","source":"Με βάση τον κώδικα που έχουμε από το [Data Loading Tutorial](https://www.kaggle.com/geoparslp/data-loading-tutorial/data):"},{"metadata":{"_cell_guid":"0c5eb0c4-da01-4491-b992-92c93e7d051c","_uuid":"6efa7170-95d9-4569-8cac-36b70de3a09a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport copy\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import SubsetRandomSampler, DataLoader\nimport re\n\n# Combine similar classes and remove underrepresented classes\nclass_mapping = {\n    'Rock': 'Rock',\n    'Psych-Rock': 'Rock',\n    'Indie-Rock': None,\n    'Post-Rock': 'Rock',\n    'Psych-Folk': 'Folk',\n    'Folk': 'Folk',\n    'Metal': 'Metal',\n    'Punk': 'Metal',\n    'Post-Punk': None,\n    'Trip-Hop': 'Trip-Hop',\n    'Pop': 'Pop',\n    'Electronic': 'Electronic',\n    'Hip-Hop': 'Hip-Hop',\n    'Classical': 'Classical',\n    'Blues': 'Blues',\n    'Chiptune': 'Electronic',\n    'Jazz': 'Jazz',\n    'Soundtrack': None,\n    'International': None,\n    'Old-Time': None\n}\n\ndef read_fused_spectrogram(spectrogram_file):\n    spectrogram = np.load(spectrogram_file)\n    return spectrogram.T\n\n\ndef read_mel_spectrogram(spectrogram_file):\n    spectrogram = np.load(spectrogram_file)[:128]\n    return spectrogram.T\n\n    \ndef read_chromagram(spectrogram_file):\n    spectrogram = np.load(spectrogram_file)[128:]\n    return spectrogram.T\n\n\nclass LabelTransformer(LabelEncoder):\n    def inverse(self, y):\n        try:\n            return super(LabelTransformer, self).inverse_transform(y)\n        except:\n            return super(LabelTransformer, self).inverse_transform([y])\n\n    def transform(self, y):\n        try:\n            return super(LabelTransformer, self).transform(y)\n        except:\n            return super(LabelTransformer, self).transform([y])\n\n\n# TODO: Comment on why padding is needed\nclass PaddingTransform(object):\n    def __init__(self, max_length, padding_value=0):\n        self.max_length = max_length\n        self.padding_value = padding_value\n\n    def __call__(self, s):\n        if len(s) == self.max_length:\n            return s\n\n        if len(s) > self.max_length:\n            return s[:self.max_length]\n\n        if len(s) < self.max_length:\n            s1 = copy.deepcopy(s)\n            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n            s1 = np.vstack((s1, pad))\n            return s1\n\n        \nclass SpectrogramDataset(Dataset):\n    def __init__(self, path, class_mapping=None, train=True, max_length=-1, read_spec_fn=read_fused_spectrogram):\n        t = 'train' if train else 'test'\n        p = os.path.join(path, t)\n        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n        self.files, self.gold_labels = self.get_files_labels(self.index, class_mapping)\n        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n        self.feat_dim = self.feats[0].shape[1]\n        self.lengths = [len(i) for i in self.feats]\n        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n        self.label_transformer = LabelTransformer()\n        if isinstance(self.gold_labels, (list, tuple)):\n            self.labels = np.array(self.label_transformer.fit_transform(self.gold_labels)).astype('int64')\n\n    def get_files_labels(self, txt, class_mapping):\n        with open(txt, 'r') as fd:\n            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n        files, labels = [], []\n        for l in lines:\n            label = l[1]\n            if class_mapping:\n                label = class_mapping[l[1]]\n            if not label:\n                continue\n            # Kaggle automatically unzips the npy.gz format so this hack is needed\n            _id = l[0].split('.')[0]\n            npy_file = '{}.fused.full.npy'.format(_id)\n            files.append(npy_file)\n            labels.append(label)\n        return files, labels\n\n    def __getitem__(self, item):\n        # TODO: Inspect output and comment on how the output is formatted\n        l = min(self.lengths[item], self.max_length)\n        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], self.gold_labels[item], l\n\n    def __len__(self):\n        return len(self.labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1934076a-3b57-4f64-a90b-297eaf0b47c9","_uuid":"442ef1e2-8cca-4bb8-bdb6-2d4bc407db93"},"cell_type":"markdown","source":"**(β)** Διαβάζοντας τα αρχεία από το path `/fma_genre_spectrograms/` έχουμε:"},{"metadata":{"_cell_guid":"6968c856-ad0e-44b1-a6c8-fac8913ae458","_uuid":"ae60338d-33de-4fc1-af30-b6b7b96478d9","trusted":true},"cell_type":"code","source":"fma_genre_spectr_path = os.path.join(data_path, \"fma_genre_spectrograms\")\n\n# print(os.listdir(fma_genre_spectr_path))\n    \ntrain_specs_mel = SpectrogramDataset(\n     fma_genre_spectr_path,\n     train=True,\n     class_mapping=class_mapping,\n     max_length=-1,\n     read_spec_fn=read_mel_spectrogram)\n\nprint(\"Train Loaded Successfuly.\", \"Train data length:\", len(train_specs_mel))\n\ntest_specs_mel = SpectrogramDataset(\n     fma_genre_spectr_path,\n     train=False,\n     class_mapping=class_mapping,\n     max_length=-1,\n     read_spec_fn=read_mel_spectrogram)\n    \nprint(\"Test Loaded Successfuly.\", \"Test data length:\", len(test_specs_mel))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(α)** Παρακάτω επιλέγουμε δυο τυχαία δείγματα με διαφορετικά labels τα οποία και θα χρησιμοποιήσουμε και για τα επόμενα ερωτήματα για να έχουμε consistancy και να μπορούμε να τα συγκρίνουμε μεταξύ τους."},{"metadata":{"_cell_guid":"49d66886-e58f-4ecb-9361-e1af78d1fe98","_uuid":"1f6c65ec-eb33-447a-b8e0-aa9fa401750f","trusted":true},"cell_type":"code","source":"import random\n\nsr = 22050\n\nrand_index_1 = random.randint(0, len(train_specs_mel)-1)\nrand_index_2 = random.randint(0, len(train_specs_mel)-1)\nrand_sample_1 = train_specs_mel[rand_index_1]\nrand_sample_2 = train_specs_mel[rand_index_2]\nwhile rand_sample_2[1] == rand_sample_1[1]:\n    rand_index_2 = random.randint(0, len(train_specs_mel)-1)\n    rand_sample_2 = train_specs_mel[rand_index_2]\n\nl1 = rand_sample_1[3]\nl2 = rand_sample_2[3]\n\n# print(specs_fused.label_transformer.inverse_transform([rand_sample_1[1]]))\n# print(rand_sample_1[2])\n# print(rand_sample_2[2])\n# print(rand_sample_1[0].shape)\n# print(rand_sample_2[0].shape)\n# print(rand_sample_1[3])\n# print(rand_sample_2[3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(γ)** Παρακάτω έχουμε τα φασματογραφήματα για τα τυχαία δείγματα:"},{"metadata":{"_cell_guid":"f6e566af-bd53-4b5e-b97c-d359f31029f9","_uuid":"11fe6d9c-421e-42fe-80d8-cdb067b4117b","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport IPython.display\nimport librosa.display\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.dpi'] = 100\n\nplt.figure(figsize=(10, 4))\n# S_dB = librosa.power_to_db(rand_sample_1[0], ref=np.max)\nlibrosa.display.specshow(rand_sample_1[0][:l1][:].T, sr=sr, x_axis='time', y_axis='mel')\nplt.colorbar()\nplt.title('Mel-frequency spectrogram of random FMA sample, genre: '+rand_sample_1[2])\nplt.tight_layout()\nplt.show()\n\n# rand_sample_1_audio = librosa.feature.inverse.mel_to_audio(rand_sample_1[0])\n# IPython.display.Audio(rand_sample_1_audio, rate=sr)\n\nplt.figure(figsize=(10, 4))\n# S_dB = librosa.power_to_db(rand_sample_2[0], ref=np.max)\nlibrosa.display.specshow(rand_sample_2[0][:l2][:].T, sr=sr, x_axis='time', y_axis='mel')\nplt.colorbar()\nplt.title('Mel-frequency spectrogram of random FMA sample, genre: '+rand_sample_2[2])\nplt.tight_layout()\nplt.show()\n\n# rand_sample_2_audio = librosa.feature.inverse.mel_to_audio(rand_sample_2[0])\n# IPython.display.Audio(rand_sample_2_audio, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79dd4ae5-f53b-4477-bb3a-93d068752273","_uuid":"a4dbcdd2-ee44-4a5f-9805-4ff77d660722"},"cell_type":"markdown","source":">Τα παραπάνω διαγράμματα μας δίνουν πληροφορία για τις συχνότητες που χρησιμοποιούνται σε κάθε τραγούδι, συναρτήσει του χρόνου καθώς και για την ένταση (πλάτος) των συχνοτήτων αυτών, ενώ δεν περιέχουν καμία πληροφορία για την φάση (κάτι που συνιστά την ανακαστακευή του ήχου μόνο από το φασματογράφημα ανακριβή)"},{"metadata":{"_cell_guid":"28682175-0271-4e5e-8cb3-6f4b1ebdd6ee","_uuid":"54cf1060-8cb8-4785-b556-152037559f35"},"cell_type":"markdown","source":"# Βήμα 2"},{"metadata":{"_cell_guid":"1738de0d-b9d3-41be-a10f-7713d5439432","_uuid":"b2af915a-0203-4f7f-9c15-d3b2d971f980"},"cell_type":"markdown","source":"**(α)** Τα χρονικά βήματα είναι η πρώτη διάσταση του πίνακα των features που φαίνεται παρακάτω και είναι ίση με $1293$ (με zero-padding)"},{"metadata":{"_cell_guid":"8b050b51-4ae3-482c-bd0a-3a8877c78960","_uuid":"9fd54a42-ca43-49d6-98d4-8b48e33be2e5","trusted":true},"cell_type":"code","source":"print(rand_sample_1[0].shape)\nprint(rand_sample_2[0].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">Παρατηρούμε πως το μέγεθος του παραπάνω πίνακα είναι αρκετά μεγάλο κάτι το οποίο θα έχει σημαντική επίδραση στον χρόνο εκπαίδευσης ενός `LSTM` και άρα αυτό το καθιστά μη αποδοτικό."},{"metadata":{"_cell_guid":"cec3eb1d-5e37-43fa-8116-2caacd230d25","_uuid":"2c274eba-616f-4337-b3a5-0f945183d0a4"},"cell_type":"markdown","source":"**(β)** Διαβάζοντας τα αρχεία από το path `/fma_genre_spectrograms_beat/` έχουμε:"},{"metadata":{"_cell_guid":"f6a5589f-ffff-45ee-b5f0-ebce7f0ada84","_uuid":"e602788a-e8f6-4ad5-8fee-5cf3d52f91c5","trusted":true},"cell_type":"code","source":"fma_genre_spectr_beat_path = os.path.join(data_path, \"fma_genre_spectrograms_beat\")\n    \n# train_specs_beat_mel = SpectrogramDataset(\n#      fma_genre_spectr_beat_path,\n#      train=True,\n#      class_mapping=class_mapping,\n#      max_length=-1,\n#      read_spec_fn=read_mel_spectrogram)\n\n# print(\"Train Loaded Successfuly.\", \"Train data length:\", len(train_specs_beat_mel))\n\n# test_specs_beat_mel = SpectrogramDataset(\n#      fma_genre_spectr_beat_path,\n#      train=False,\n#      class_mapping=class_mapping,\n#      max_length=-1,\n#      read_spec_fn=read_mel_spectrogram)\n    \n# print(\"Test Loaded Successfuly.\", \"Test data length:\", len(test_specs_beat_mel))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ebf56f4b-5040-49f1-8e9f-d163624b128c","_uuid":"845ee5bc-bc89-45a8-8eb8-1c4dd1651880","trusted":true},"cell_type":"code","source":"# rand_sample_1 = train_specs_beat_mel[rand_index_1]\n# rand_sample_2 = train_specs_beat_mel[rand_index_2]\n\n# l1 = rand_sample_1[3]\n# l2 = rand_sample_2[3]\n\n# print(rand_sample_1[0].shape)\n# print(rand_sample_2[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"81252637-23d4-4bf6-987e-ec8c811c3718","_uuid":"da1e0903-dc83-4d12-bb26-0eacdd7c0afa","trusted":true},"cell_type":"code","source":"# import IPython.display\n# import librosa.display\n# import matplotlib.pyplot as plt\n# plt.rcParams['figure.dpi'] = 100\n\n# sr = 22050\n\n# plt.figure(figsize=(10, 4))\n# # S_dB = librosa.power_to_db(rand_sample_1[0], ref=np.max)\n# librosa.display.specshow(rand_sample_1[0][:l1][:].T, sr=sr, x_axis='time', y_axis='mel')\n# plt.colorbar()\n# plt.title('Mel-frequency spectrogram (beat-synced) of random FMA sample, genre: '+rand_sample_1[2])\n# plt.tight_layout()\n# plt.show()\n\n\n# plt.figure(figsize=(10, 4))\n# # S_dB = librosa.power_to_db(rand_sample_2[0], ref=np.max)\n# librosa.display.specshow(rand_sample_2[0][:l2][:].T, sr=sr, x_axis='time', y_axis='mel')\n# plt.colorbar()\n# plt.title('Mel-frequency spectrogram (beat-synced) of random FMA sample, genre: '+rand_sample_2[2])\n# plt.tight_layout()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ef9073bd-ad14-4307-970e-f02e32648c7c","_uuid":"2b36124d-dedc-4ade-a06f-4a383d356aa2"},"cell_type":"markdown","source":"# Βήμα 3"},{"metadata":{},"cell_type":"markdown","source":"Για τα χρωμογραφήματα που περιέχουν πληροφορίες σχετικά με τις νότες του κάθε τραγουδιού έχουμε:"},{"metadata":{},"cell_type":"markdown","source":"Για την πλήρη πληροφορία:"},{"metadata":{"_cell_guid":"4933f922-a11d-48f1-9d18-bdf5d614d7e8","_uuid":"658d6c8b-361f-4240-b4bc-4e905c8094b5","trusted":true},"cell_type":"code","source":"# chromas_train = SpectrogramDataset(\n#      fma_genre_spectr_path,\n#      train=True,\n#      class_mapping=class_mapping,\n#      max_length=-1,\n#      read_spec_fn=read_chromagram)\n\n# print(\"Train Loaded Successfuly.\", \"Train data length:\", len(chromas_train))\n\n# chromas_test = SpectrogramDataset(\n#      fma_genre_spectr_path,\n#      train=False,\n#      class_mapping=class_mapping,\n#      max_length=-1,\n#      read_spec_fn=read_chromagram)\n\n# print(\"Test Loaded Successfuly.\", \"Test data length:\", len(chromas_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rand_sample_1 = chromas_train[rand_index_1]\n# rand_sample_2 = chromas_train[rand_index_2]\n\n# l1 = rand_sample_1[3]\n# l2 = rand_sample_2[3]\n\n# print(rand_sample_1[0].shape)\n# print(rand_sample_2[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33ad41d3-dd0b-4766-b078-190fd27e0ba1","_uuid":"70fd615f-5fa2-4bf3-b15d-b7526ea52346","scrolled":false,"trusted":true},"cell_type":"code","source":"# import IPython.display\n# import librosa.display\n# import matplotlib.pyplot as plt\n# plt.rcParams['figure.dpi'] = 100\n\n# sr = 22050\n\n# plt.figure(figsize=(10, 4))\n# # S_dB = librosa.power_to_db(rand_sample_1[0], ref=np.max)\n# librosa.display.specshow(rand_sample_1[0][:l1][:].T, sr=sr, x_axis='time', y_axis='chroma')\n# plt.colorbar()\n# plt.title('Chroma of random FMA sample, genre: '+rand_sample_1[2])\n# plt.tight_layout()\n# plt.show()\n\n\n# plt.figure(figsize=(10, 4))\n# # S_dB = librosa.power_to_db(rand_sample_2[0], ref=np.max)\n# librosa.display.specshow(rand_sample_2[0][:l2][:].T, sr=sr, x_axis='time', y_axis='chroma')\n# plt.colorbar()\n# plt.title('Chroma of random FMA sample, genre: '+rand_sample_2[2])\n# plt.tight_layout()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Για τα beat-synced δεδομένα:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# chromas_beat_train = SpectrogramDataset(\n#      fma_genre_spectr_beat_path,\n#      train=True,\n#      class_mapping=class_mapping,\n#      max_length=-1,\n#      read_spec_fn=read_chromagram)\n\n# print(\"Train Loaded Successfuly.\", \"Train data length:\", len(chromas_beat_train))\n\n# chromas_beat_test = SpectrogramDataset(\n#      fma_genre_spectr_beat_path,\n#      train=False,\n#      class_mapping=class_mapping,\n#      max_length=-1,\n#      read_spec_fn=read_chromagram)\n\n# print(\"Test Loaded Successfuly.\", \"Test data length:\", len(chromas_beat_test))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ca3197f8-a881-4dc2-b4b8-31c5de0d7cbf","_uuid":"594f8106-369c-458d-8209-a800a00652f2","trusted":true},"cell_type":"code","source":"# rand_sample_1 = chromas_beat_train[rand_index_1]\n# rand_sample_2 = chromas_beat_train[rand_index_2]\n\n# l1 = rand_sample_1[3]\n# l2 = rand_sample_2[3]\n\n# print(rand_sample_1[0].shape)\n# print(rand_sample_2[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"99473fd8-037c-4023-a23c-97dec29d6360","_uuid":"784de906-3520-4aea-94ce-404f4f61d0c0","trusted":true},"cell_type":"code","source":"# import IPython.display\n# import librosa.display\n# import matplotlib.pyplot as plt\n# plt.rcParams['figure.dpi'] = 100\n\n# sr = 22050\n\n# plt.figure(figsize=(10, 4))\n# # S_dB = librosa.power_to_db(rand_sample_1[0], ref=np.max)\n# librosa.display.specshow(rand_sample_1[0][:l1][:].T, sr=sr, x_axis='time', y_axis='chroma')\n# plt.colorbar()\n# plt.title('Chroma of random (beat-synced) FMA sample, genre: '+rand_sample_1[2])\n# plt.tight_layout()\n# plt.show()\n\n\n# plt.figure(figsize=(10, 4))\n# # S_dB = librosa.power_to_db(rand_sample_2[0], ref=np.max)\n# librosa.display.specshow(rand_sample_2[0][:l2][:].T, sr=sr, x_axis='time', y_axis='chroma')\n# plt.colorbar()\n# plt.title('Chroma of random (beat-synced) FMA sample, genre: '+rand_sample_2[2])\n# plt.tight_layout()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"db278986-7703-4b83-895c-ff64e99e6278","_uuid":"9a033b21-b637-4286-9da7-c5899e42ecbf"},"cell_type":"markdown","source":"# Βήμα 4"},{"metadata":{},"cell_type":"markdown","source":"**(α)** Στη συνέχεια γίνεται χρήση της προαναφερθείσας έτοιμης υλοποίησης `PyTorch Dataset` η οποία διαβάζει τα δεδομένα και επιστρέφει τα δείγματα. Παρατηρούμε πως αφού τα δείγματα μας δεν έχουν όλα το ίδιο πλήθος features είναι απαραίτητη η χρήση του `zero padding`, μιας και για το στάδιο της εκπαίδευσης του `LSTM` πρέπει όλα τα δεδομένα να έχουν όλα τις ίδιες διαστάσειες. Στην επιστροφή των δεδομένων μέσω του getter που έχει οριστεί, εκτός από τα features, τα μετασχηματισμένα labels (σε Integers) και το πραγματικό μήκος του κάθε δείγματος (χωρίς zero-padding δηλαδή) έχουμε προσθέσει και την πραγματική τιμή του label ως string (του genre)."},{"metadata":{},"cell_type":"markdown","source":"**(β)** Με την παράμετρο `class_mapping` κάνουμε **_map_** μερικές κλάσεις σε κάποιες ήδη υπάρχουσες που μπορούν να θεωρηθούν ευρύτερες με σκοπό την συγχώνευση όμοιων μεταξύ τους κλάσεων, ή αφαιρούμε εντελώς αυτές που παρατηρούμε ότι αντιπροσωπεύονται από πολύ μικρό αριθμό δειγμάτων."},{"metadata":{"trusted":true},"cell_type":"code","source":"# specs_without_mapping = SpectrogramDataset(\n#      fma_genre_spectr_path,\n#      train=True,\n#      class_mapping={},\n#      max_length=-1,\n#      read_spec_fn=read_mel_spectrogram)\n\n# print(\"Train Loaded Successfuly.\", \"Train data length:\", len(specs_without_mapping))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(γ)** Παρακάτω φαίνονται τα ιστογράμματα που αφορούν τον αριθμό δειγμάτων που αντιστοιχούν στην εκάστοτε κλάση **χωρίς** και **με** συγχώνευση κλάσεων:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Initialize subplots\n# fig, axs = plt.subplots(1,2,figsize=(20,7))\n# fig.suptitle(\"Number of Samples per Genre\", size=22, fontweight='demibold' )\n\n# # Before Class Merging\n# unique, counts = np.unique(specs_without_mapping.gold_labels, return_counts=True)\n# axs[0].set_title(\"(a) Without Genre-Merging\", size=15)\n# axs[0].bar(unique, counts, width=0.5, color='#0080FF', alpha=1.0, edgecolor='k', linewidth=0.5)\n# [tick.set_rotation(90) for tick in axs[0].get_xticklabels()]\n# axs[0].tick_params(labelsize=17)\n# axs[0].grid(linewidth=0.3, alpha=0.5)\n\n# # After Class Merging\n# unique, counts = np.unique(train_specs_mel.gold_labels, return_counts=True)\n# axs[1].set_title(\"(b) With Genre-Merging\", size=15)\n# axs[1].bar(unique, counts, width=0.5, color='#0080FF', alpha=1.0, edgecolor='k', linewidth=0.5)\n# [tick.set_rotation(90) for tick in axs[1].get_xticklabels()]\n# axs[1].tick_params(labelsize=17)\n# axs[1].grid(linewidth=0.3, alpha=0.5)\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8363cde2-e5fa-49dc-9db6-d1e909a03747","_uuid":"9762478b-79aa-4c78-bce6-5a3d80b9c78a"},"cell_type":"markdown","source":"# Βήμα 5-6"},{"metadata":{},"cell_type":"markdown","source":"Παρακάτω έχουμε μια υλοποίηση για ένα `LSTM` δίκτυο:"},{"metadata":{"_cell_guid":"1957d0a6-da47-49ef-8fe2-d4b5f50f8eca","_uuid":"e10b7ae5-6fe9-43c7-87eb-0ef7f5f3d35f","trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\n\nclass BasicLSTM(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, dropout_prob=0.0, \n                 num_layers=1, bidirectional=False, isPackedSequence=False):\n        super(BasicLSTM, self).__init__()\n        \n        self.dropout_prob = dropout_prob\n        self.bidirectional = bidirectional\n        self.feature_size = hidden_dim * 2 if self.bidirectional else hidden_dim\n        self.num_layers = num_layers\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n        self.isPackedSequence = isPackedSequence\n        \n        # Initialize the LSTM, Dropout, Output layers\n        \n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n                                dropout=dropout_prob, batch_first=True, bidirectional= bidirectional)\n        \n        self.drop = nn.Dropout(p=dropout_prob)\n        \n        self.fc = nn.Linear(self.feature_size, self.output_dim)\n        \n\n    def forward(self, x, lengths):\n        \"\"\" \n            x : 3D numpy array of dimension N x L x D\n                N: batch index\n                L: sequence index\n                D: feature index\n\n            lengths: N x 1\n         \"\"\"\n        \n        N, L, D = x.size()\n        \n        if self.isPackedSequence:\n            x = pack_padded_sequence(x, lengths, batch_first=True)\n        \n        out, _ = self.lstm(x)\n        \n        if self.isPackedSequence:\n            out, _ = pad_packed_sequence(out, batch_first=True)\n        \n        dropped = self.drop(out)\n        \n        last = self.last_timestep(dropped, lengths)\n        \n        last_outputs = self.fc(last)\n        \n        # You must have all of the outputs of the LSTM\n        # but you need only the last one (that does not exceed the sequence length)\n        # To get it use the last_timestep method\n        # Then pass it through the remaining network\n              \n        return last_outputs\n    \n    \n\n    def last_timestep(self, outputs, lengths, bidirectional=False):\n        \"\"\"\n            Returns the last output of the LSTM taking into account the zero padding\n        \"\"\"\n        if bidirectional:\n            forward, backward = self.split_directions(outputs)\n            last_forward = self.last_by_index(forward, lengths)\n            last_backward = backward[:, 0, :]\n            # Concatenate and return - maybe add more functionalities like average\n            return torch.cat((last_forward, last_backward), dim=-1)\n        else:\n            return self.last_by_index(outputs, lengths)\n\n    @staticmethod\n    def split_directions(outputs):\n        direction_size = int(outputs.size(-1) / 2)\n        forward = outputs[:, :, :direction_size]\n        backward = outputs[:, :, direction_size:]\n        return forward, backward\n\n    @staticmethod\n    def last_by_index(outputs, lengths):\n        # Index of the last output for each sequence.\n        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n                                               outputs.size(2)).unsqueeze(1)\n        return outputs.gather(1, idx).squeeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}\\n\\n')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\\n\\n')\n        torch.save(model.state_dict(), 'checkpoint.pt')\n        self.val_loss_min = val_loss","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6e59651d-74bf-415b-881a-564f20582815","_uuid":"30ce79b4-c2e6-4ede-853b-6e7baaba5154","trusted":true},"cell_type":"code","source":"import math\nimport sys\n\ndef progress(loss, epoch, batch, batch_size, dataset_size):\n    \"\"\"\n    Print the progress of the training for each epoch\n    \"\"\"\n    batches = math.ceil(float(dataset_size) / batch_size)\n    count = batch * batch_size\n    bar_len = 40\n    filled_len = int(round(bar_len * count / float(dataset_size)))\n\n    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n\n    status = 'Epoch {}, Loss: {:.4f}'.format(epoch, loss)\n    _progress_str = \"\\r \\r [{}] ...{}\".format(bar, status)\n    sys.stdout.write(_progress_str)\n    sys.stdout.flush()\n\n    if batch == batches:\n        print()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"61d32960-989e-4490-95d3-7878744a1f23","_uuid":"e12f8e9f-1ac1-4179-8c6c-8e932e62f9cd","trusted":true},"cell_type":"code","source":"import torch\nfrom torch.autograd import Variable\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n\ndef train_dataset(_epoch, dataloader, model, loss_function, optimizer):\n    \n    model.train()\n    running_loss = 0.0\n\n    # obtain the model's device ID\n    device = next(model.parameters()).device\n\n    for index, batch in enumerate(dataloader, 1):\n\n        # get the inputs (batch)\n        inputs, labels, _, lengths = batch\n        \n#         inputs = inputs.double()\n        \n        # Step 1 - move the batch tensors to the right device and also sort by length for packed sequence\n        \n#         if model.isPackedSequence:\n#             sorted_by_len = sorted(zip(lengths, labels, inputs), key=lambda pair: pair[0], reverse=True) \n#             lengths = Variable(torch.tensor([x for x, _, _ in sorted_by_len])).to(device)\n#             labels = Variable(torch.tensor([x for _, x, _ in sorted_by_len])).to(device)\n#             inputs = Variable(torch.cat([x.view(1, x.size(0), -1) for _, _, x in sorted_by_len])).to(device)\n#         else:            \n        inputs = Variable(inputs).to(device).float()\n        labels = Variable(labels).to(device)\n        lengths = Variable(lengths).to(device)\n\n        optimizer.zero_grad()\n\n        # Step 2 - forward pass: y' = model(x)\n        outputs = model(inputs, lengths)\n\n        # Step 3 - compute loss: L = loss_function(y, y')\n        loss = loss_function(outputs, labels)\n\n        # Step 4 - backward pass: compute gradient wrt model parameters\n        loss.backward()\n\n        # Step 5 - update weights\n        optimizer.step()\n\n        running_loss += loss.data.item()\n\n        # print statistics\n        progress(loss=loss.data.item(),\n                 epoch=_epoch,\n                 batch=index,\n                 batch_size=dataloader.batch_size,\n                 dataset_size=len(dataloader.dataset))\n\n    return running_loss / index\n\n\ndef eval_dataset(dataloader, model, loss_function):\n    \n    # IMPORTANT: switch to eval mode\n    # disable regularization layers, such as Dropout\n    model.eval()\n    running_loss = 0.0\n\n    y_pred = []  # the predicted labels\n    y = []  # the gold labels\n\n    # obtain the model's device ID\n    device = next(model.parameters()).device\n\n    # IMPORTANT: in evaluation mode, we don't want to keep the gradients\n    # so we do everything under torch.no_grad()\n    with torch.no_grad():\n        for index, batch in enumerate(dataloader, 1):\n\n            # get the inputs (batch)\n            inputs, labels, _, lengths = batch\n            \n#             inputs = inputs.double()\n\n            # Step 1 - move the batch tensors to the right device and also sort by length for packed sequence\n            \n#             if model.isPackedSequence:\n#                 sorted_by_len = sorted(zip(lengths, labels, inputs), key=lambda pair: pair[0], reverse=True) \n#                 lengths = Variable(torch.tensor([x for x, _, _ in sorted_by_len])).to(device)\n#                 labels = Variable(torch.tensor([x for _, x, _ in sorted_by_len])).to(device)\n#                 inputs = Variable(torch.cat([x.view(1, x.size(0), -1) for _, _, x in sorted_by_len])).to(device)\n#             else:            \n            inputs = Variable(inputs).to(device).float()\n            labels = Variable(labels).to(device)\n            lengths = Variable(lengths).to(device)\n                    \n            # Step 2 - forward pass: y' = model(x)\n            outputs = model(inputs, lengths)\n\n            # Step 3 - compute loss.\n            # We compute the loss only for inspection (compare train/test loss)\n            # because we do not actually backpropagate in test time\n            loss = loss_function(outputs, labels)\n\n            # Step 4 - make predictions (class = argmax of posteriors)\n            _, posibol = torch.max(outputs.data, 1)\n\n            # Step 5 - collect the predictions, gold labels and batch loss\n            y_pred.extend(list(posibol.data.cpu().numpy().squeeze()))\n            y.extend(list(labels.data.cpu().numpy().squeeze()))\n\n\n            running_loss += loss.data.item()\n\n    return running_loss / index, (y_pred, y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7c003e61-5c76-4121-b1b3-f6bb66d50263","_uuid":"946feec6-cd23-40e2-9ed6-f901404edd48","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\nimport time\n\ndef train_and_val_model(EPOCHS, train_loader, val_loader, model, loss_function, optimizer, early_stopping_limit=0):\n\n    total_train_loss = []\n    total_val_loss = []\n    \n    if early_stopping_limit:\n        early_stopping = EarlyStopping(patience=early_stopping_limit, verbose=True)\n    \n    start_time = time.time()\n    \n    for epoch in range(1, EPOCHS + 1):\n        # train the model for one epoch\n        train_dataset(epoch, train_loader, model, loss_function, optimizer)\n\n        # evaluate the performance of the model\n        train_loss, (y_train_pred, y_train_gold) = eval_dataset(train_loader, model, loss_function)\n        print(\"Train Set: loss={:.4f}\".format(train_loss))\n\n        val_loss, (y_val_pred, y_val_gold) = eval_dataset(val_loader, model, loss_function)\n        print(\"Validation Set: loss={:.4f}, accuracy={:.4f}\\n\".format(val_loss, \n                                                                      accuracy_score(y_val_gold, y_val_pred)))\n\n\n        total_train_loss.append(train_loss)\n        total_val_loss.append(val_loss)\n        \n        if early_stopping_limit:\n            early_stopping(val_loss, model)\n        \n            if early_stopping.early_stop:\n                print(\"Early stopping...\")\n                break\n\n    if early_stopping_limit:        \n        # load the last checkpoint with the best model\n        model.load_state_dict(torch.load('checkpoint.pt'))\n        \n    print(\"\\nTotal train and validation time: {:.2f} seconds\".format((time.time() - start_time)))\n    \n    return total_train_loss, total_val_loss\n\n\ndef test_model(test_loader, model, loss_function, set):\n    \n    test_loss, (y_test_pred, y_test_gold) = eval_dataset(test_loader, model, loss_function)\n    print(\"\\n\"+set+\" Set: loss={:.4f}, accuracy={:.4f}, f1-macro={:.4f}\".format(test_loss,\n                accuracy_score(y_test_gold, y_test_pred), f1_score(y_test_gold, y_test_pred, average='macro')))\n    \n    return y_test_pred, y_test_gold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport itertools\nimport matplotlib.pyplot as plt\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n#         print(\"Normalized confusion matrix\")\n#     else:\n#         print('Confusion matrix, without normalization')\n\n#     print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Για την εκπαίδευση των παρακάτω δεδομένων θα χρησιμοποιήσουμε ένα `Bidirectional LSTM` δίκτυο με δύο layers, $batch\\ size = 64$ και με την εκπαίδευση να γίνεται για $25$ εποχές."},{"metadata":{"_cell_guid":"832af654-e4da-47f6-964d-e993ca85f609","_uuid":"ca66d537-ba66-4aa6-b2d9-3741c6f2a54b","trusted":true},"cell_type":"code","source":"# from torch.utils.data import DataLoader\n# import numpy as np\n# import torch\n\n# BATCH_SIZE = 64\n# EPOCHS = 25\n\n# # if your computer has a CUDA compatible gpu use it, otherwise use the cpu\n# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# print('DEVICE:', DEVICE)\n# if torch.cuda.is_available():\n#     print(  'cuda Version:', torch.version.cuda,\n#             '\\nn_cuda =', torch.cuda.device_count(),\n#             '\\nCuda Name(s):', torch.cuda.get_device_name(0)    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Για το διαχωρισμό των δεδομένων σε train και validation με ποσοστα $80\\%-20\\%$ θα κάνουμε χρήση της συνάρτησης `train_test_split()` της βιβλιοθήκης `sklearn`"},{"metadata":{},"cell_type":"markdown","source":"**(α)** Έχονντας ως  είσοδο τα __φασματογραφήματα__ του συνόλου εκπαίδευσης έχουμε:"},{"metadata":{"_cell_guid":"d9d56ad3-9561-4470-8717-831470bd6692","_uuid":"fb04abf0-399b-4d0a-8cfc-6b9d1b34bb6d","scrolled":true,"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# train_specs, val_specs = train_test_split(train_specs_mel, test_size=0.2)\n\n# train_loader = DataLoader(train_specs, batch_size=BATCH_SIZE, shuffle=True)\n# val_loader = DataLoader(val_specs, batch_size=BATCH_SIZE, shuffle=True)\n# test_loader = DataLoader(test_specs_mel, batch_size=BATCH_SIZE, shuffle=True)\n\n# INPUT_SIZE = train_specs_mel.feat_dim\n# OUTPUT_SIZE = len(list(set(train_specs_mel.labels)))\n\n# model = BasicLSTM(input_dim=INPUT_SIZE, hidden_dim=20, output_dim=OUTPUT_SIZE, num_layers=2, bidirectional=True).to(DEVICE)\n\n# loss_function = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# total_train_loss, total_val_loss = train_and_val_model(EPOCHS, train_loader, val_loader, model, \n#                                                         loss_function, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_val_pred, y_val_gold = test_model(val_loader, model, loss_function, \"Validation\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"88f84220-c89e-4873-9781-59349f177bb5","_uuid":"1218238e-829b-4973-9acb-0ca94373214b","trusted":true},"cell_type":"code","source":"# y_test_pred, y_test_gold = test_model(test_loader, model, loss_function, \"Test\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import classification_report\n\n# labels = list(set(test_specs_mel.gold_labels))\n# print(classification_report(y_test_gold, y_test_pred, target_names=labels))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c97d244-83cd-4e73-925a-1afdbcf4a9c8","_uuid":"bf62aa91-964c-4d25-81af-5328f322a5ad","trusted":true},"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix\n\n\n# conf_mat_val = confusion_matrix(y_val_gold, y_val_pred)\n# plot_confusion_matrix(conf_mat_val, labels, title='Confusion matrix for Validation Set')\n\n# conf_mat_test = confusion_matrix(y_test_gold, y_test_pred)\n# plot_confusion_matrix(conf_mat_test, labels, title='Confusion matrix for Test Set')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(β)** Έχονντας ως  είσοδο τα __beat-synced spectrograms__ του συνόλου εκπαίδευσης έχουμε:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# train_specs, val_specs = train_test_split(train_specs_beat_mel, test_size=0.2)\n\n# train_loader = DataLoader(train_specs, batch_size=BATCH_SIZE, shuffle=True)\n# val_loader = DataLoader(val_specs, batch_size=BATCH_SIZE, shuffle=True)\n# test_loader = DataLoader(test_specs_beat_mel, batch_size=BATCH_SIZE, shuffle=True)\n\n# INPUT_SIZE = train_specs_beat_mel.feat_dim\n# OUTPUT_SIZE = len(list(set(train_specs_beat_mel.labels)))\n\n# model = BasicLSTM(input_dim=INPUT_SIZE, hidden_dim=20, output_dim=OUTPUT_SIZE, num_layers=2, bidirectional=True).to(DEVICE)\n\n# loss_function = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# total_train_loss, total_val_loss = train_and_val_model(EPOCHS, train_loader, val_loader, model, \n#                                                         loss_function, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_val_pred, y_val_gold = test_model(val_loader, model, loss_function, \"Validation\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"88f84220-c89e-4873-9781-59349f177bb5","_uuid":"1218238e-829b-4973-9acb-0ca94373214b","trusted":true},"cell_type":"code","source":"# y_test_pred, y_test_gold = test_model(test_loader, model, loss_function, \"Test\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import classification_report\n\n# labels = list(set(test_specs_mel.gold_labels))\n# print(classification_report(y_test_gold, y_test_pred, target_names=labels))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c97d244-83cd-4e73-925a-1afdbcf4a9c8","_uuid":"bf62aa91-964c-4d25-81af-5328f322a5ad","trusted":true},"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix\n\n# conf_mat_val = confusion_matrix(y_val_gold, y_val_pred)\n# plot_confusion_matrix(conf_mat_val, labels, title='Confusion matrix for Validation Set')\n\n# conf_mat_test = confusion_matrix(y_test_gold, y_test_pred)\n# plot_confusion_matrix(conf_mat_test, labels, title='Confusion matrix for Test Set')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(γ)** Έχονντας ως  είσοδο τα __χρωμογραφήματα (beat-synced)__ του συνόλου εκπαίδευσης έχουμε:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# train_specs, val_specs = train_test_split(chromas_beat_train, test_size=0.2)\n\n# train_loader = DataLoader(train_specs, batch_size=BATCH_SIZE, shuffle=True)\n# val_loader = DataLoader(val_specs, batch_size=BATCH_SIZE, shuffle=True)\n# test_loader = DataLoader(chromas_beat_test, batch_size=BATCH_SIZE, shuffle=True)\n\n# INPUT_SIZE = chromas_beat_train.feat_dim\n# OUTPUT_SIZE = len(list(set(chromas_beat_train.labels)))\n\n# model = BasicLSTM(input_dim=INPUT_SIZE, hidden_dim=20, output_dim=OUTPUT_SIZE, num_layers=2, bidirectional=True).to(DEVICE)\n\n# loss_function = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# total_train_loss, total_val_loss = train_and_val_model(EPOCHS, train_loader, val_loader, model, \n#                                                         loss_function, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_val_pred, y_val_gold = test_model(val_loader, model, loss_function, \"Validation\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"88f84220-c89e-4873-9781-59349f177bb5","_uuid":"1218238e-829b-4973-9acb-0ca94373214b","trusted":true},"cell_type":"code","source":"# y_test_pred, y_test_gold = test_model(test_loader, model, loss_function, \"Test\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import classification_report\n\n# labels = list(set(test_specs_mel.gold_labels))\n# print(classification_report(y_test_gold, y_test_pred, target_names=labels))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c97d244-83cd-4e73-925a-1afdbcf4a9c8","_uuid":"bf62aa91-964c-4d25-81af-5328f322a5ad","trusted":true},"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix\n\n# conf_mat_val = confusion_matrix(y_val_gold, y_val_pred)\n# plot_confusion_matrix(conf_mat_val, labels, title='Confusion matrix for Validation Set')\n\n# conf_mat_test = confusion_matrix(y_test_gold, y_test_pred)\n# plot_confusion_matrix(conf_mat_test, labels, title='Confusion matrix for Test Set')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(δ) (Bonus)** Έχονντας ως  είσοδο τα __concatenated (beat-synced) features__ του συνόλου εκπαίδευσης έχουμε:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_specs_fused = SpectrogramDataset(\n     fma_genre_spectr_beat_path,\n     train=True,\n     class_mapping=class_mapping,\n     max_length=-1,\n     read_spec_fn=read_fused_spectrogram)\n\nprint(\"Train Loaded Successfuly.\", \"Train data length:\", len(train_specs_fused))\n\ntest_specs_fused = SpectrogramDataset(\n     fma_genre_spectr_beat_path,\n     train=False,\n     class_mapping=class_mapping,\n     max_length=-1,\n     read_spec_fn=read_fused_spectrogram)\n    \nprint(\"Test Loaded Successfuly.\", \"Test data length:\", len(test_specs_fused))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# train_specs, val_specs = train_test_split(train_specs_fused, test_size=0.2)\n\n# train_loader = DataLoader(train_specs, batch_size=BATCH_SIZE, shuffle=True)\n# val_loader = DataLoader(val_specs, batch_size=BATCH_SIZE, shuffle=True)\n# test_loader = DataLoader(test_specs_fused, batch_size=BATCH_SIZE, shuffle=True)\n\n# INPUT_SIZE = train_specs_fused.feat_dim\n# OUTPUT_SIZE = len(list(set(train_specs_fused.labels)))\n\n# model = BasicLSTM(input_dim=INPUT_SIZE, hidden_dim=20, output_dim=OUTPUT_SIZE, num_layers=2, bidirectional=True).to(DEVICE)\n\n# loss_function = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# total_train_loss, total_val_loss = train_and_val_model(50, train_loader, val_loader, model, \n#                                                         loss_function, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_val_pred, y_val_gold = test_model(val_loader, model, loss_function, \"Validation\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"88f84220-c89e-4873-9781-59349f177bb5","_uuid":"1218238e-829b-4973-9acb-0ca94373214b","trusted":true},"cell_type":"code","source":"# y_test_pred, y_test_gold = test_model(test_loader, model, loss_function, \"Test\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import classification_report\n\n# labels = list(set(test_specs_mel.gold_labels))\n# print(classification_report(y_test_gold, y_test_pred, target_names=labels))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c97d244-83cd-4e73-925a-1afdbcf4a9c8","_uuid":"bf62aa91-964c-4d25-81af-5328f322a5ad","trusted":true},"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix\n\n# conf_mat_val = confusion_matrix(y_val_gold, y_val_pred)\n# plot_confusion_matrix(conf_mat_val, labels, title='Confusion matrix for Validation Set')\n\n# conf_mat_test = confusion_matrix(y_test_gold, y_test_pred)\n# plot_confusion_matrix(conf_mat_test, labels, title='Confusion matrix for Test Set')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">Παρατηρούμε πως συγκρίνοντας τους χρόνους εκπαίδευσης και παρατηρώντας τις μετρικές στο εκάστοτε test set δεν έχει νόημα η εκπαίδευση στα full data. Παρατηρούμε επίσης πως χρησιμοποιώντας την ίδια αρχιτεκτονική αλλά δίνοντας ως input τα concatenated beat-synced features, πετυχαίνουμε αρκετά καλύτερη επίδοση σε σχέση με όλες τις προηγούμενες δοκιμές κατι αναμενόμενο μιας και πρόκειται για συνδυασμό γνώσης/features."},{"metadata":{},"cell_type":"markdown","source":"# Βήμα 6"},{"metadata":{},"cell_type":"markdown","source":"**(δ)** Το `Accuracy` ενός μοντέλου πάνω σε ένα σύνολο δεδομένων δείχνει τι ποσοστό των προβλέψεων είναι σωστές και το ορίζουμε ως εξής:\n\n$$Accuracy = \\frac{Number\\ of\\ correct\\ predictions}{Total\\ number\\ of\\ predictions}$$\n\n\n\nΘεωρούμε μια οποιαδήποτε κλάση $c$ θετική (possitive) και όλες τις υπόλοιπες αρνητικές (negative). Ορίζουμε τα παρακάτω:\n\n- True Positive (**TP**): Είναι το πλήθος των δειγμάτων για τα οποία το μοντέλο προβλέπει σωστά ότι ανήκουν στην θετική κλάση.\n\n- True Negative (**TN**): Είναι το πλήθος των δειγμάτων για τα οποία το μοντέλο προβλέπει σωστά ότι δεν ανήκουν στη θετική κλάση.\n\n- False Positive (**FP**): Είναι το πλήθος των δειγμάτων για τα οποία το μοντέλο προβλέπει λανθασμένα ότι ανήκουν στην θετική κλάση.\n\n- False Negative (**FN**): Είναι το πλήθος των δειγμάτων για τα οποία το μοντέλο προβλέπει λανθασμένα ότι δεν ανήκουν στην θετική κλάση. \n\n\nΤο `Precision` για την κλάση $c$ ενός μοντέλου πάνω σε ένα σύνολο δεδομένων δείχνει τι ποσοστό των θετικών προβλέψεων ήταν πραγματικά σωστές και το ορίζουμε ως εξής:\n\n$$Precision(c) = \\frac{TP}{TP+FP}$$\n\nΤο `Recall` για την κλάση $c$ ενός μοντέλου πάνω σε ένα σύνολο δεδομένων δείχνει τι ποσοστό των δεδομένων που ανήκουν στην θετική κλάση πράγματι προβλέφθηκε σωστά και το ορίζουμε ως εξής:\n\n$$Recall(c) = \\frac{TP}{TP+FN}$$\n\nΤο `F1-score` για την κλάση $c$ ενός μοντέλου πάνω σε ένα σύνολο δεδομένων είναι ένα μέτρο της ακρίβειας το οποίο εξαρτάται από τα Precision και Recall και μάλιστα ορίζεται ως ο αρμονικός τους μέσος:\n\n$$F1-score(c) = 2\\cdot\\frac{Precision \\cdot Recall}{Precision+Recall}$$\n\n\nΣτην περίπτωση του `Macro-Average` υπολογίζουμε μια μετρική επιτυχίας, μεταχειριζόμενοι όλες τις κλάσεις ισότιμα, παρά το διαφορετικό πλήθος δεδομένων που πιθανότατα αντιστοιχεί στην καθεμία. Ουσιαστικά, τα `Macro-Averaged` `Precision` και `Recall` ορίζονται αντίστοιχα ως ο μέσος όρος των επιμέρους $Precision(c)$ και $Recall(c)$ και εν συνεχεία το `Macro-Averaged` `F1-score` ορίζεται ως ο αρμονικός μέσος των `Macro-Averaged` `Precision` και `Recall`.\n\nΣτην περίπτωση του `Micro-Average` υπολογίζουμε μια μετρική επιτυχίας, λαμβάνοντας υπόψη τη συνεισφορά της κάθε κλάσης. Ουσιαστικά, τα `Micro-Averaged` `Precision`, `Recall` και `F1-score` ισούνται όλα με το `Accuracy` που ορίσαμε παραπάνω.\n\n\n\n\nΣτην περίπτωση του `Macro-Average`, το `F1-score` ενδέχεται να απέχει πολύ από το `Accuracy`. Αυτό μπορεί να συμβεί εάν η συνεισφορά της κάθε κλάσης στο σύνολο των δεδομένων είναι αρκετά ανισομερής.\n\nΑντιθέτως, στην περίπτωση του `Micro-Average`, το `F1-score` είναι αδύνατο να αποκλίνει από το `Accuracy` μιας και ταυτίζονται. \n\nΗ περίπτωση που τα `Macro-Averaged F1-score` και `Micro-Averaged F1-score` αποκλίνουν οφείλεται σε ανισομερή συνεισφορά της εκάστοτε κλάσης, πράγμα που ταυτίζεται με την παραπάνω πρόταση πέρι απόκλισης `Macro-Average F1-score` και `Accuracy` μιας και τα `Micro-Averaged F1-score` και `Accuracy` αποτελούν το ίδιο πράγμα.\n\n\n\nΑρχικά, γνωρίζουμε ότι δε μπορούμε να μεγιστοποιήσουμε και το Precision και το Recall ενός μοντέλου, βελτιώνοντας το ένα θα χειροτερεύει το άλλο. Βέβαια, ανάλογα με το πρόβλημα μερικές φορές το Recall μας ενδιαφέρει περισσότερο από το Precision και αντιστρόφως Για παράδειγμα, ένα μοντέλο για να αποφανθούμε αν ένας ασθενής έχει ένα σπάνιο είδος καρκίνου πρέπει οπωσδήποτε να έχει υψηλό Recall, καθώς επιθυμούμε οπωσδήποτε να ελαχιστοποιηθούν τα False Negatives. Από την άλλη, ένα μοντέλο για να κάνει συστάσεις βίντεο στους χρήστες μιας διαδικτυακής πλατφόρμας προτιμάμε να έχει υψηλό Precision αφού θέλουμε ελαχιστοποίηση των False Positives (και τα False Negatives δε μας αφορούν ιδιαίτερα).\n\nΚάποιο είδος `Averaged F1-score` (είτε το Accuracy) είναι αρκετό για την επιλογή μοντέλου όταν αναζητούμε μια ισορροπία μεταξύ των Precision και Recall. Ωστόσο, σε πολύ ειδικές περιπτώσεις που είναι αναγαίο να ελαχιστοποιηθούν όσο γίνεται περισσότερο είτε τα False Negatives,  είτε τα False Positives τότε θα πρέπει να επικεντρωθούμε στην μεγιστοποίηση του Recall και του Precision αντίστοιχα."},{"metadata":{},"cell_type":"markdown","source":"# Βήμα 7"},{"metadata":{},"cell_type":"markdown","source":"**(α)** Από τα παρακάτω στιγμιότυπα από την εκπαίδευση ενός CNN στο MNIST dataset (μέσω του [ConvNetJS](https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html)) έχουμε:"},{"metadata":{},"cell_type":"markdown","source":"**(β)** Για το 4 layer 2D CNN έχουμε:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n\nclass ConvNNet(Module):   \n    def __init__(self):\n        super(ConvNNet, self).__init__()\n\n        self.cnn_layers = Sequential(\n            # Defining a 2D convolution layer\n            Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n            BatchNorm2d(4),\n            ReLU(inplace=True),\n            MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.linear_layers = Sequential(\n            Linear(4 * 7 * 7, 10)\n        )\n\n    # Defining the forward pass    \n    def forward(self, x, lengths):\n        x = self.cnn_layers(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear_layers(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport numpy as np\nimport torch\n\nBATCH_SIZE = 64\nEPOCHS = 10\n\n# if your computer has a CUDA compatible gpu use it, otherwise use the cpu\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint('DEVICE:', DEVICE)\nif torch.cuda.is_available():\n    print(  'cuda Version:', torch.version.cuda,\n            '\\nn_cuda =', torch.cuda.device_count(),\n            '\\nCuda Name(s):', torch.cuda.get_device_name(0)    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_specs, val_specs = train_test_split(train_specs_mel, test_size=0.2)\n\ntrain_loader = DataLoader(train_specs, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_specs, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_specs_mel, batch_size=BATCH_SIZE, shuffle=True)\n\nINPUT_SIZE = train_specs_mel.feat_dim\nOUTPUT_SIZE = len(list(set(train_specs_mel.labels)))\n\nmodel = ConvNNet().to(DEVICE)\n\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\ntotal_train_loss, total_val_loss = train_and_val_model(EPOCHS, train_loader, val_loader, model, \n                                                        loss_function, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred, y_test_gold = test_model(test_loader, model, loss_function, \"Test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nlabels = list(set(test_specs_mel.gold_labels))\nprint(classification_report(y_test_gold, y_test_pred, target_names=labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Βήμα 8"},{"metadata":{},"cell_type":"markdown","source":"**(α)** Για το multitask dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport copy\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import SubsetRandomSampler, DataLoader\nimport re\n\ndef read_fused_spectrogram(spectrogram_file):\n    spectrogram = np.load(spectrogram_file)\n    return spectrogram.T\n\n\ndef read_mel_spectrogram(spectrogram_file):\n    spectrogram = np.load(spectrogram_file)[:128]\n    return spectrogram.T\n\n    \ndef read_chromagram(spectrogram_file):\n    spectrogram = np.load(spectrogram_file)[128:]\n    return spectrogram.T\n\n\n# TODO: Comment on why padding is needed\nclass PaddingTransform(object):\n    def __init__(self, max_length, padding_value=0):\n        self.max_length = max_length\n        self.padding_value = padding_value\n\n    def __call__(self, s):\n        if len(s) == self.max_length:\n            return s\n\n        if len(s) > self.max_length:\n            return s[:self.max_length]\n\n        if len(s) < self.max_length:\n            s1 = copy.deepcopy(s)\n            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n            s1 = np.vstack((s1, pad))\n            return s1\n\n        \nclass MultitaskDataset(Dataset):\n    def __init__(self, path, train=True, max_length=-1, read_spec_fn=read_fused_spectrogram):\n        t = 'train' if train else 'test'\n        p = os.path.join(path, t)\n        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n        self.files, self.valences, self.energies, self.danceabilities = self.get_files_labels(self.index)\n        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]\n        self.feat_dim = self.feats[0].shape[1]\n        self.lengths = [len(i) for i in self.feats]\n        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n\n    def get_files_labels(self, txt):\n        with open(txt, 'r') as fd:\n            lines = [l.rstrip().split(',') for l in fd.readlines()[1:]]\n        files, valences, energies, danceabilities = [], [], [], []\n        for l in lines:\n            _id = l[0]\n            valency = l[1]\n            energy = l[2]\n            danceability = l[3]\n            # Kaggle automatically unzips the npy.gz format so this hack is needed\n            npy_file = '{}.fused.full.npy'.format(_id)\n            files.append(npy_file)\n            valences.append(valency)\n            energies.append(energy)\n            danceabilities.append(danceability)\n        return files, valences, energies, danceabilities\n\n#     def __getitem__(self, item):\n#         # TODO: Inspect output and comment on how the output is formatted\n#         l = min(self.lengths[item], self.max_length)\n#         return self.zero_pad_and_stack(self.feats[item]), self.labels[item], self.gold_labels[item], l\n\n    def __len__(self):\n        return len(self.valences)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Επειδή έχουμε labels μόνο για τα train δεδομένα θα εργαστούμε με αυτά."},{"metadata":{"trusted":true},"cell_type":"code","source":"multitask_path = os.path.join(data_path, \"multitask_dataset\")\n\n# print(os.listdir(multitask_path))\n    \ntrain_specs_mel = MultitaskDataset(\n     multitask_path,\n     train=True,\n     max_length=-1,\n     read_spec_fn=read_mel_spectrogram)\n\nprint(\"Train Loaded Successfuly.\", \"Train data length:\", len(train_specs_mel))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(ε)** Για το Spearman correlation έχουμε:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import spearmanr\n\nrho, pval = spearmanr(x2n,y2n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8ff38c8b-f719-4709-981e-f86387c7330a","_uuid":"8c6ebfee-b3c4-4b42-9b22-e70a88c398da"},"cell_type":"markdown","source":"---"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}